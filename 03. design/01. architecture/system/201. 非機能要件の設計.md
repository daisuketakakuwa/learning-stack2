#  Design Requirements
01. Move Data -> Between CPU/RAM/Disks, Between machines over network
02. Store Data -> DB? FileSystems? Which data algorithm?
03. Transform Data
## What is good design?
There's not always a correct answer, we have to think in terms of **trade-offs** in the following measurement.

01. Availabilityã€ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã€‘(å¯ç”¨æ€§)
02. Reliabilityã€æ™‚é–“ã€‘(ä¿¡é ¼æ€§)
03. Fault tolerance(è€éšœå®³æ€§)
04. Redundancy(unnecessary/å†—é•·æ€§)
05. Throughput(ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ/å‡¦ç†èƒ½åŠ›/å‡¦ç†é‡)
06. Latency(ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼/é…å»¶æ™‚é–“)

<img width="700px" src="https://storage.googleapis.com/zenn-user-upload/6b8a4e491451-20230406.png" />

âœ…The more tolerant for faults, the more reliable the server is.<br>
âœ…By having redundancy, we are able to have fault tolerance.

## Availability(å¯ç”¨æ€§)ã€€ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸

æ•°å€¤ï¼š(uptime/(uptime + downtime)) * 100

99% .... Not good because the service down for 3.65 days<br>
99.99% ... Very good because the service down for 5 minutes

## Reliability(ä¿¡é ¼æ€§)ã€€æ™‚é–“
ä¿¡é ¼æ€§ã‚’ç¤ºã™ã®ã¯ã€MTBFã€‘

MTBFï¼šMean Time Before Failure<br>
MTTRï¼šMean Time To Repair

MTBF = (total elapsed time â€“ sum of downtime)/number of failures

500æ™‚é–“ã«1å›ã€600æ™‚é–“ã«1å›ã€400æ™‚é–“ã«1å›æ•…éšœãŒèµ·ããŸå ´åˆã€3ã¤ã®æ•…éšœã®å¹³å‡ã§ã‚ã‚‹500æ™‚é–“ãŒMTBFã«ãªã‚‹ã®ã§ã€**å€¤ãŒå¤§ãã„ã»ã©ä¿¡é ¼æ€§ã¯é«˜ã„ã€‚**

éšœå®³ã®ç™ºç”Ÿã®ã—ã«ãã•<br>
Probablity system will fail.<br>
ãƒ»OS update<br>
ãƒ»DDoS attacks<br>
So that it's better to have multiple servers NOT to have **SPOF/Single Point of Failure**

<img width="700px" src="https://storage.googleapis.com/zenn-user-upload/c6bc1c2f401f-20230123.png" />

## Fault Tolerance(è€éšœå®³æ€§) â˜…å¯ç”¨æ€§/ä¿¡é ¼æ€§ã«ç›´çµã™ã‚‹
Our system is tolerant to failures of portions of the system.<br>
ä¸€éƒ¨ã®ã‚µãƒ¼ãƒãŒãƒ€ã‚¦ãƒ³ã—ã¦ã‚‚ã‚µãƒ¼ãƒ“ã‚¹ç¨¼åƒã‚’ç¶šã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ãªã“ã¨ã€‚<br>

ä»–ã«ã©ã†ã„ã£ãŸæ–¹æ³•ãŒã‚ã‚‹ã‹ï¼Ÿ<br>
ãƒ»ã‚µãƒ¼ãƒ(API/DB)ã®å°æ•°ã‚’è¤‡æ•°ã«ã€‚<br>
ãƒ»ãƒ€ã‚¦ãƒ³ã—ã¦ã‚‹ã‚µãƒ¼ãƒã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒè¡Œã‹ãªã„ã‚ˆã†ã«LoadBalancerã€‚<br>
ãƒ»ç‰©ç†çš„ã«åˆ¥ã®åœ°åŸŸã«ã‚µãƒ¼ãƒã‚’åˆ†æ•£ã—ã¦ãŠãã€‚

### Fault-Tolerant DATABASE System
Primary-Replication/Standbyæ§‹æˆ
â†’ Primaryæ©ŸãŒæ­»ã‚“ã ã¨ãã«ã€Standbyæ©Ÿã«**Failover**ã€‚â€»Hot/Warm/Cold
â†’ Standbyæ©Ÿã§**Cold Backup**

https://zenn.dev/crsc1206/articles/f1028b342caa5a

## Fault-Tolerant Design for WEB Applications
### 1. Load Balancing
Load balancing solutions allow an application to run on **multiple network nodes**, removing the concern about a single point of failure. -> âœ…LoadBalanceã®ä»•çµ„ã¿ãŒã‚ã‚‹ã“ã¨ã§ã€åœ°ç†çš„ã«/ç•°ãªã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã”ã¨ã«ã‚µãƒ¼ãƒã‚’åˆ†æ•£ã§ãã‚‹ã€‚
### 2. Failover
For true fault tolerance with zero downtime, you need to implement â€œhotâ€ failover, which transfers workloads instantly to a working backup system. If maintaining a constantly active standby system is not an option, you can use â€œwarmâ€ or â€œcoldâ€ failover, in which a backup system takes time to load and start running workloads.

## Redundancy(å†—é•·æ€§)
When we have two servers, basically it works only by a single server so the second one is unnecessary/redundant. But when the first server failed, we are able to have fault tolerance by a redundant server(second server)ğŸ‘

## Throughput(ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ/å‡¦ç†èƒ½åŠ›/å‡¦ç†é‡)
å˜ä½æ™‚é–“å½“ãŸã‚Šã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã®å‡¦ç†é‡ã‚„é€šä¿¡å›ç·šã®ãƒ‡ãƒ¼ã‚¿è»¢é€é‡ã®ã“ã¨ã€‚<br>
In general it means the amount of operations or data we can handle over the period.<br>

ğŸ‘‰How many requests our server can handle per seconds?<br>
ğŸ‘‰How many concurrent users can could our system handle per seconds?<br>

<img width="700px" src="https://storage.googleapis.com/zenn-user-upload/35e4bacb0e18-20230123.png" />

For servers, RPS/**Requests** per seconds<br>
For databases, QPS/**Queries** per seconds<br>
For a data pipelines, BPS/**Bytes** per seconds

## Latency(é…å»¶æ™‚é–“)
throughput: something divided by something<br>
latency: just period of time it takes for an operation to complete

<img width="700px" src="https://storage.googleapis.com/zenn-user-upload/20ea5055eb2e-20230123.png" />

âœ…Having a cache -> lower latency<br>
âœ…Distributed server in the world -> each people can talk to the nearby serverğŸ‘

